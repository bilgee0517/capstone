{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Set new cache directories\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/ephemeral/hf_cache\"\n",
    "os.environ[\"HF_HOME\"] = \"/ephemeral/transformers_cache\"\n",
    "os.environ[\"TMPDIR\"] = \"/ephemeral/tmp\"\n",
    "\n",
    "# Ensure the directories exist\n",
    "os.makedirs(\"/ephemeral/hf_cache\", exist_ok=True)\n",
    "os.makedirs(\"/ephemeral/transformers_cache\", exist_ok=True)\n",
    "os.makedirs(\"/ephemeral/tmp\", exist_ok=True)\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer,Trainer,TrainingArguments,DataCollatorForLanguageModeling,DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_first_lines_text(file_path, num_lines=5):\n",
    "    \"\"\"\n",
    "    Reads and prints the first `num_lines` lines from a plain text file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i in range(num_lines):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break  # Stop if file has fewer than num_lines\n",
    "            print(f\"Line {i+1}: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: MONGOLIAN: Ямар нөхцөлд амьжиргааны түвшний үнэлгээнд дахин орох вэ?\n",
      "Line 2: ENGLISH: What is the case with living standards?\n",
      "Line 3: \n",
      "Line 4: MONGOLIAN: Уг аяны үргэлжлэл болгож \"Бид хамтдаа\" үндэсний форумыг ирэх долоо хоногт зохион байгуулахаар болжээ.\n",
      "Line 5: ENGLISH: As a continuation of the campaign, we will organize a national forum \"We are together\" next week.\n"
     ]
    }
   ],
   "source": [
    "show_first_lines_text(\"mn_corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db8e1a6007047979c3a6cb39be684b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 19\u001b[0m\n\u001b[1;32m     11\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m     12\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,                    \u001b[38;5;66;03m# Enable 4-bit quantization\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,            \u001b[38;5;66;03m# Options: 'nf4' (recommended) or 'fp4'\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,       \u001b[38;5;66;03m# Nested quantization for higher accuracy\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m     \u001b[38;5;66;03m# Mixed-precision type: 'fp16', 'bf16', etc.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 3. Load model in 4-bit\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# auto-distributes across GPU(s) if available\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:262\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4319\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4312\u001b[0m     (\n\u001b[1;32m   4313\u001b[0m         model,\n\u001b[1;32m   4314\u001b[0m         missing_keys,\n\u001b[1;32m   4315\u001b[0m         unexpected_keys,\n\u001b[1;32m   4316\u001b[0m         mismatched_keys,\n\u001b[1;32m   4317\u001b[0m         offload_index,\n\u001b[1;32m   4318\u001b[0m         error_msgs,\n\u001b[0;32m-> 4319\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4326\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4330\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4331\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4339\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4340\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4897\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4895\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4896\u001b[0m         fixed_state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fix_state_dict_keys_on_load(state_dict)\n\u001b[0;32m-> 4897\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfixed_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4903\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4904\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4905\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4906\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4907\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4908\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4913\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4915\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:825\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# We convert floating dtypes to the `dtype` passed except for float8_e4m3fn type. We also want to keep the buffers/params\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# in int/uint/bool and not cast them.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m is_param_float8_e4m3fn \u001b[38;5;241m=\u001b[39m is_torch_e4m3fn_available \u001b[38;5;129;01mand\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat8_e4m3fn\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_param_float8_e4m3fn:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    827\u001b[0m         keep_in_fp32_modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m    832\u001b[0m     ):\n\u001b[1;32m    833\u001b[0m         param \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to the Hugging Face Hub\n",
    "login(token=\"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\")\n",
    "\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# 1. Create a quantization config for 4-bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                    # Enable 4-bit quantization\n",
    "    bnb_4bit_quant_type=\"nf4\",            # Options: 'nf4' (recommended) or 'fp4'\n",
    "    bnb_4bit_use_double_quant=True,       # Nested quantization for higher accuracy\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\"     # Mixed-precision type: 'fp16', 'bf16', etc.\n",
    ")\n",
    "\n",
    "# 3. Load model in 4-bit\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"  # auto-distributes across GPU(s) if available\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BloomTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "# 2. Load tokenizer\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"Billyyy/llama_8K_extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "merged_dataset = load_dataset(\"Billyyy/llama_8K_extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_sequences_with_text(dataset, tokenizer, max_length=1024):\n",
    "    \"\"\"\n",
    "    Merge sequences in a dataset while keeping 'text' and 'input_ids' aligned.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Dataset): Hugging Face Dataset with 'text' and 'input_ids'.\n",
    "        tokenizer: Tokenizer used to tokenize the text.\n",
    "        max_length (int): Maximum length for merged sequences.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with merged 'text' and 'input_ids'.\n",
    "    \"\"\"\n",
    "    merged_texts = []\n",
    "    merged_input_ids = []\n",
    "    current_text = []\n",
    "    current_input_ids = []\n",
    "\n",
    "    for text, input_ids in zip(dataset[\"text\"], dataset[\"input_ids\"]):\n",
    "        # Check if adding the current sequence exceeds the max length\n",
    "        if len(current_input_ids) + len(input_ids) > max_length:\n",
    "            # Append the merged sequences\n",
    "            merged_texts.append(\" \".join(current_text))\n",
    "            merged_input_ids.append(current_input_ids[:max_length])\n",
    "            # Reset for the next sequence\n",
    "            current_text = []\n",
    "            current_input_ids = []\n",
    "        \n",
    "        # Extend the current sequence\n",
    "        current_text.append(text)\n",
    "        current_input_ids.extend(input_ids)\n",
    "    \n",
    "    # Add the final batch if it exists\n",
    "    if current_input_ids:\n",
    "        merged_texts.append(\" \".join(current_text))\n",
    "        merged_input_ids.append(current_input_ids[:max_length])\n",
    "\n",
    "    return {\"text\": merged_texts, \"input_ids\": merged_input_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=27): 100%|██████████| 955519/955519 [00:13<00:00, 72378.89 examples/s]\n",
      "Map (num_proc=27): 100%|██████████| 50291/50291 [00:00<00:00, 51975.37 examples/s]\n",
      "Map (num_proc=27): 100%|██████████| 955519/955519 [00:04<00:00, 221512.98 examples/s]\n",
      "Map (num_proc=27): 100%|██████████| 50291/50291 [00:00<00:00, 96506.03 examples/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.remove_columns(\"attention_mask\")\n",
    "\n",
    "# Add 'input_ids' column if not already in the dataset\n",
    "if \"input_ids\" not in dataset.column_names:\n",
    "    dataset = dataset.map(\n",
    "        lambda examples: {\"input_ids\": tokenizer(examples[\"text\"], truncation=True, padding=False, max_length=256)[\"input_ids\"]},\n",
    "        batched=True,\n",
    "        num_proc=27\n",
    "    )\n",
    "\n",
    "# Apply the merging function\n",
    "merged_dataset = dataset.map(\n",
    "    lambda batch: merge_sequences_with_text(batch, tokenizer, max_length=256),\n",
    "    batched=True, \n",
    "    num_proc=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 645131\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 34004\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset.remove_columns(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2325c3703bd3430fa15551b76269501f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdba4aeb0ad240db81f6dd6ce218a433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/216 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71d8d27663744e4ac618371af00bab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/216 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd79a7c4c3d4ec7954b293b8da3afbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/216 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee9f07a04b2490c87f99f5284a50b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376cf858e2f84a87b8edc869eff69530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c47bccca04a423fb81c0abc75a4b336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/423 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Billyyy/llama_8K_extended/commit/298dc49a0351e7853c5357e4cc5971b82ce2eed8', commit_message='Upload dataset', commit_description='', oid='298dc49a0351e7853c5357e4cc5971b82ce2eed8', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Billyyy/llama_8K_extended', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Billyyy/llama_8K_extended'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset.push_to_hub(\"Billyyy/llama_8K_extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenizes each line in the dataset.\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], truncation=True, padding=True, max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090e826f234d46bca2a5b5a07c389784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=27):   0%|          | 0/645131 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a46d69d8065493dbf0317f7688e1cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=27):   0%|          | 0/34004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_dataset = merged_dataset.map(tokenize_function, batched=True, num_proc=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<mn> Хамгийн анх \"Халуун сэтгэл\" киноны найруулагч Л.Энхбаяр ах 2006 онд намайг кинонд уриад, гол дүрээ өгөхөд нь маш их баярлаж байлаа. <en>The first director of \"Hot Soul\", L.Enkhbayar, was excited to thank me for the role of the film in 2006. <mn> Манай хойд хєршийг хувьд ч гэсэн сурталчилгааны зорилгоор хуурамч мєнгийг ашиглах туршлагыг хэрэгжvvлж байжээ. <en>In addition, our northern neighbors have been involved in the use of counterfeit money for advertising.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset['train'][60000]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training Arguments -------------------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/ephemeral/llama_3B_translation\",  \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    logging_dir=\"/workspace/logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"wandb\",\n",
    "    remove_unused_columns=False,\n",
    "    group_by_length=False,\n",
    "    \n",
    "    # A100-specific optimizations\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    ddp_find_unused_parameters=False,\n",
    "\n",
    ")\n",
    "\n",
    "# 6. Data Collator for Masked Language Modeling -------------------\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# 7. Trainer Initialization ---------------------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=merged_dataset[\"train\"],\n",
    "    eval_dataset=merged_dataset[\"eval\"], \n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 645131\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc851ba7bd24b8aa0061906f620f863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 2. Load Pretrained Tokenizer & Model -----------------------------\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"  # Change if using another model\n",
    "TOKENIZER_PATH = \"Billyyy/llama_8K_extended\" # Path to your trained tokenizer\n",
    "DATASET_PATH = \"/workspace/labeled_corpus.txt\" \n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")\n",
    "\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "# 3. Resize Model's Embedding Layer -------------------------------\n",
    "old_vocab_size = model.get_input_embeddings().num_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing model embeddings from 128256 → 135126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if vocab_size > old_vocab_size:\n",
    "    print(f\"Resizing model embeddings from {old_vocab_size} → {vocab_size}\")\n",
    "    model.resize_token_embeddings(vocab_size)\n",
    "\n",
    "# Freeze all layers except embedding\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze entire model\n",
    "\n",
    "# Enable training for embedding layer only\n",
    "model.get_input_embeddings().weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 8,086,540,288\n",
      "Trainable parameters: 553,476,096\n",
      "Percentage of trainable parameters: 6.84%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    \"\"\"Returns the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Percentage of trainable parameters: {100 * trainable_params / total_params:.2f}%\")\n",
    "    \n",
    "    return trainable_params\n",
    "\n",
    "# Example Usage (after loading your model)\n",
    "trainable_params = count_trainable_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 777, in convert_to_tensors\n    tensor = as_tensor(value)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 739, in as_tensor\n    return torch.tensor(value)\nValueError: too many dimensions 'str'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/data/data_collator.py\", line 45, in __call__\n    return self.torch_call(features)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/data/data_collator.py\", line 943, in torch_call\n    batch = pad_without_fast_tokenizer_warning(\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/data/data_collator.py\", line 66, in pad_without_fast_tokenizer_warning\n    padded = tokenizer.pad(*pad_args, **pad_kwargs)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 3397, in pad\n    return BatchEncoding(batch_outputs, tensor_type=return_tensors)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 241, in __init__\n    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 793, in convert_to_tensors\n    raise ValueError(\nValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/trainer.py:2500\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2498\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2499\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2500\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2502\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/transformers/trainer.py:5180\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5180\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5182\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/accelerate/data_loader.py:564\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 564\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1480\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1505\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1505\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/torch/_utils.py:733\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 777, in convert_to_tensors\n    tensor = as_tensor(value)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 739, in as_tensor\n    return torch.tensor(value)\nValueError: too many dimensions 'str'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/data/data_collator.py\", line 45, in __call__\n    return self.torch_call(features)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/data/data_collator.py\", line 943, in torch_call\n    batch = pad_without_fast_tokenizer_warning(\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/data/data_collator.py\", line 66, in pad_without_fast_tokenizer_warning\n    padded = tokenizer.pad(*pad_args, **pad_kwargs)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 3397, in pad\n    return BatchEncoding(batch_outputs, tensor_type=return_tensors)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 241, in __init__\n    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)\n  File \"/workspace/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 793, in convert_to_tensors\n    raise ValueError(\nValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = merged_dataset.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 645131\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 34004\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 **Sample 1:**\n",
      "Input IDs: [128000, 14066, 77, 29, 81529, 129063, 220, 128972, 129025, 130337, 220, 128594, 129051, 220, 128665, 134437, 130829, 129613, 220, 128989, 129461, 135069, 220, 129807, 131538, 220, 131143, 133635, 132778, 131651, 220, 131061, 128480, 129051, 134429, 128530, 129461, 129126, 220, 128813, 131160, 220, 128480, 133572, 130829, 131208, 131636, 128480, 129461, 131814, 129113, 45458, 130226, 128594, 130829, 130226, 129461, 220, 132551, 128989, 129461, 133545, 130829, 131143, 134429, 131061, 134429, 220, 128480, 131613, 128594, 129051, 220, 128697, 133208, 128594, 220, 130337, 134600, 129325, 220, 130829, 131061, 134429, 131763, 220, 134801, 128594, 130829, 133635, 129461, 133635, 129461, 130337, 220, 134899, 128480, 128382, 129461, 129461, 134076, 134429, 129561, 220, 134429, 128812, 128594, 220, 128972, 129025, 130337, 13, 366, 268, 43093, 3786, 374, 7373, 18641, 449, 44539, 89108, 6444, 889, 527, 1101, 39075, 18250, 1534, 449, 264, 11336, 3786, 13, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded Text: <mn> Энэ карт нь санхүүгийн илүү эрх чөлөөтэй амьдралын хэв маягийгэрхэмлэдэг Монгол харилцагчдад маань бүрэн тохирохоос гадна хөнгөлөлт урамшууллуудаар дүүрэн карт. <en>This card is fully compatible with Mongolian customers who are also financially liberalized with a discount card.\n",
      "Labels: [128000, 14066, 77, 29, 81529, 129063, 220, 128972, 129025, 130337, 220, 128594, 129051, 220, 128665, 134437, 130829, 129613, 220, 128989, 129461, 135069, 220, 129807, 131538, 220, 131143, 133635, 132778, 131651, 220, 131061, 128480, 129051, 134429, 128530, 129461, 129126, 220, 128813, 131160, 220, 128480, 133572, 130829, 131208, 131636, 128480, 129461, 131814, 129113, 45458, 130226, 128594, 130829, 130226, 129461, 220, 132551, 128989, 129461, 133545, 130829, 131143, 134429, 131061, 134429, 220, 128480, 131613, 128594, 129051, 220, 128697, 133208, 128594, 220, 130337, 134600, 129325, 220, 130829, 131061, 134429, 131763, 220, 134801, 128594, 130829, 133635, 129461, 133635, 129461, 130337, 220, 134899, 128480, 128382, 129461, 129461, 134076, 134429, 129561, 220, 134429, 128812, 128594, 220, 128972, 129025, 130337, 13, 366, 268, 43093, 3786, 374, 7373, 18641, 449, 44539, 89108, 6444, 889, 527, 1101, 39075, 18250, 1534, 449, 264, 11336, 3786, 13, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "📝 **Sample 2:**\n",
      "Input IDs: [128000, 14066, 77, 29, 57855, 131160, 130337, 130226, 128697, 132556, 220, 134632, 128480, 130981, 128594, 129613, 220, 131061, 129082, 128989, 129461, 130337, 128935, 220, 131061, 129082, 128989, 129461, 220, 131923, 130033, 134935, 130050, 220, 133635, 128480, 130067, 220, 128480, 128552, 220, 131061, 131160, 130337, 130226, 128697, 132556, 128594, 134331, 220, 129840, 129025, 131143, 128712, 220, 129232, 129063, 220, 2636, 220, 130337, 133635, 130829, 134735, 130829, 220, 128697, 134820, 128594, 220, 128697, 130226, 129461, 220, 133635, 130067, 133635, 134429, 129606, 220, 7007, 11, 220, 134115, 129477, 128480, 220, 130008, 129461, 220, 128557, 132789, 130829, 131061, 128480, 129126, 220, 130337, 132663, 133761, 220, 134445, 220, 130337, 133635, 130829, 134735, 130829, 220, 128697, 130226, 129461, 130829, 130226, 129082, 220, 132961, 130829, 133019, 128594, 220, 128697, 133214, 131763, 13, 366, 268, 16761, 5951, 706, 7319, 279, 3430, 315, 220, 7007, 323, 1063, 3117, 8614, 44995, 311, 220, 134445, 386, 6542, 824, 5951, 1603, 279, 2883, 596, 8420, 1051, 51249, 369, 264, 5951, 8577, 13, 366, 22524, 29, 117482, 106, 129063, 128594, 131208, 220, 128813, 129461, 134454, 134429, 11, 220, 128697, 128989, 220, 134115, 131763, 129461, 130337, 220, 134429, 133214, 130050, 131763, 131061, 220, 131143, 220, 135125, 128438, 220, 131061, 129461, 134429, 131613, 130829, 220, 134429, 131061, 131160, 130337, 132275, 133214, 220, 130829, 131814, 129082, 220, 131538, 132549, 130041, 13, 366, 268, 66430, 8206, 11, 358, 656, 539, 1390, 311, 13454, 856, 16930, 13, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded Text: <mn> Автобус компанийн ажилтнууд ажил хаяхаас өмнө микро автобусны зорчих үнэ 500 төгрөг байсан бол өнөөдөр 700, зарим хол шугамын тарифыг 1000 төгрөг болгож өсгөсөн байна. <en>The bus has increased the price of 700 and some far-line tariffs to 1000 MNT per bus before the company's employees were tossed for a bus trip. <mn> Үнэнийг хэлэхэд, би заналт дайснаа ч миний алдааг давтаасай гэж хүсэхгүй. <en>In truth, I do not want to repeat my mistake.\n",
      "Labels: [128000, 14066, 77, 29, 57855, 131160, 130337, 130226, 128697, 132556, 220, 134632, 128480, 130981, 128594, 129613, 220, 131061, 129082, 128989, 129461, 130337, 128935, 220, 131061, 129082, 128989, 129461, 220, 131923, 130033, 134935, 130050, 220, 133635, 128480, 130067, 220, 128480, 128552, 220, 131061, 131160, 130337, 130226, 128697, 132556, 128594, 134331, 220, 129840, 129025, 131143, 128712, 220, 129232, 129063, 220, 2636, 220, 130337, 133635, 130829, 134735, 130829, 220, 128697, 134820, 128594, 220, 128697, 130226, 129461, 220, 133635, 130067, 133635, 134429, 129606, 220, 7007, 11, 220, 134115, 129477, 128480, 220, 130008, 129461, 220, 128557, 132789, 130829, 131061, 128480, 129126, 220, 130337, 132663, 133761, 220, 134445, 220, 130337, 133635, 130829, 134735, 130829, 220, 128697, 130226, 129461, 130829, 130226, 129082, 220, 132961, 130829, 133019, 128594, 220, 128697, 133214, 131763, 13, 366, 268, 16761, 5951, 706, 7319, 279, 3430, 315, 220, 7007, 323, 1063, 3117, 8614, 44995, 311, 220, 134445, 386, 6542, 824, 5951, 1603, 279, 2883, 596, 8420, 1051, 51249, 369, 264, 5951, 8577, 13, 366, 22524, 29, 117482, 106, 129063, 128594, 131208, 220, 128813, 129461, 134454, 134429, 11, 220, 128697, 128989, 220, 134115, 131763, 129461, 130337, 220, 134429, 133214, 130050, 131763, 131061, 220, 131143, 220, 135125, 128438, 220, 131061, 129461, 134429, 131613, 130829, 220, 134429, 131061, 131160, 130337, 132275, 133214, 220, 130829, 131814, 129082, 220, 131538, 132549, 130041, 13, 366, 268, 66430, 8206, 11, 358, 656, 539, 1390, 311, 13454, 856, 16930, 13, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "📝 **Sample 3:**\n",
      "Input IDs: [128000, 14066, 77, 29, 57855, 131318, 131061, 128594, 130829, 133214, 220, 133214, 128480, 131061, 130829, 130337, 220, 130050, 135069, 129461, 129613, 220, 130829, 132068, 131160, 131061, 128594, 220, 128756, 130829, 134076, 129461, 129051, 220, 134429, 128735, 129461, 131061, 128594, 59842, 31274, 102357, 12, 134429, 57855, 129025, 134429, 131143, 128989, 129461, 128665, 220, 131763, 128480, 129126, 220, 130829, 132401, 134429, 131208, 220, 128756, 130829, 131223, 128594, 220, 129461, 220, 134429, 129968, 13, 366, 268, 66430, 279, 22791, 21313, 2192, 9395, 351, 11, 279, 1566, 2380, 16374, 1051, 16689, 311, 279, 20302, 304, 279, 20302, 13, 366, 22524, 29, 35448, 134429, 129968, 43896, 131143, 128989, 130194, 129082, 131961, 130829, 220, 134429, 131814, 128480, 129082, 128989, 129082, 11, 220, 131814, 129461, 134429, 131814, 131160, 220, 128480, 134916, 220, 134115, 131061, 130829, 131483, 220, 133635, 130829, 131143, 128712, 220, 131160, 128438, 220, 128813, 128480, 132751, 128594, 220, 128712, 131814, 134429, 220, 133214, 129082, 220, 128697, 133214, 130829, 131613, 220, 131061, 129082, 13, 366, 268, 29, 7184, 11, 26946, 343, 53478, 374, 1633, 27207, 430, 568, 690, 539, 3041, 709, 13, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded Text: <mn> Архангай аймагт сүүлийн гурван сонгууль дараалан УИХ-д Ардчилсан намын гишүүдийг сонгосон л доо. <en>In the Arkhangai aimag, the last three elections were elected to the Parliament in the Parliament. <mn> Одоо Ичиножёог дэмжиж, элдэв мэх заагаад өгчих вий хэмээн ихэд айж байгаа аж. <en>Now, Ichigoyo is very scared that he will not give up.\n",
      "Labels: [128000, 14066, 77, 29, 57855, 131318, 131061, 128594, 130829, 133214, 220, 133214, 128480, 131061, 130829, 130337, 220, 130050, 135069, 129461, 129613, 220, 130829, 132068, 131160, 131061, 128594, 220, 128756, 130829, 134076, 129461, 129051, 220, 134429, 128735, 129461, 131061, 128594, 59842, 31274, 102357, 12, 134429, 57855, 129025, 134429, 131143, 128989, 129461, 128665, 220, 131763, 128480, 129126, 220, 130829, 132401, 134429, 131208, 220, 128756, 130829, 131223, 128594, 220, 129461, 220, 134429, 129968, 13, 366, 268, 66430, 279, 22791, 21313, 2192, 9395, 351, 11, 279, 1566, 2380, 16374, 1051, 16689, 311, 279, 20302, 304, 279, 20302, 13, 366, 22524, 29, 35448, 134429, 129968, 43896, 131143, 128989, 130194, 129082, 131961, 130829, 220, 134429, 131814, 128480, 129082, 128989, 129082, 11, 220, 131814, 129461, 134429, 131814, 131160, 220, 128480, 134916, 220, 134115, 131061, 130829, 131483, 220, 133635, 130829, 131143, 128712, 220, 131160, 128438, 220, 128813, 128480, 132751, 128594, 220, 128712, 131814, 134429, 220, 133214, 129082, 220, 128697, 133214, 130829, 131613, 220, 131061, 129082, 13, 366, 268, 29, 7184, 11, 26946, 343, 53478, 374, 1633, 27207, 430, 568, 690, 539, 3041, 709, 13, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "📝 **Sample 4:**\n",
      "Input IDs: [128000, 14066, 77, 29, 100980, 128480, 129127, 128585, 220, 131143, 220, 130379, 131143, 128989, 128594, 348, 132580, 129613, 220, 128697, 132504, 128545, 220, 128697, 133214, 130829, 134076, 129461, 131061, 128480, 129082, 220, 128594, 129051, 220, 131814, 129063, 220, 130008, 130337, 129126, 220, 131814, 128594, 130829, 129807, 220, 134429, 130043, 220, 130337, 132789, 128594, 220, 130610, 130033, 131538, 131763, 135117, 220, 128697, 129022, 131143, 220, 134454, 129461, 129985, 220, 131061, 129082, 13, 366, 268, 29, 11458, 11, 6617, 14016, 6137, 311, 10205, 1633, 6051, 304, 279, 3363, 13, 366, 22524, 29, 51418, 132935, 129025, 220, 129082, 128989, 128594, 128813, 129063, 220, 130226, 129461, 130226, 128594, 220, 131538, 132789, 131160, 128989, 129461, 133545, 128530, 129127, 220, 130337, 130226, 130829, 129461, 130226, 130577, 220, 131143, 220, 135102, 128594, 128438, 220, 131923, 128480, 130829, 131613, 129461, 131061, 130829, 131143, 129613, 220, 130637, 130829, 132751, 220, 131763, 128884, 134429, 131160, 129127, 128585, 220, 128697, 128895, 129461, 135069, 129461, 129113, 220, 129063, 130829, 131814, 128594, 13, 366, 268, 29, 1548, 11335, 304, 1690, 3953, 11, 719, 568, 374, 279, 832, 889, 27772, 813, 477, 1077, 29315, 596, 3560, 21676, 13, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded Text: <mn> Ямартай ч орчин vеийн барилга байгууламж нь энэ хотын энгэр дээр тун саяхнаас босч эхэлсэн аж. <en>However, modern buildings began to rise very recently in the city. <mn> Тэрээр жинхэнэ олон хувилцараар тоглодог ч зүүний хамгаалагчийн үүргээ найдвартай биелүүлдэг нэгэн. <en>He plays in many games, but he is the one who performs his or her defender's role safely.\n",
      "Labels: [128000, 14066, 77, 29, 100980, 128480, 129127, 128585, 220, 131143, 220, 130379, 131143, 128989, 128594, 348, 132580, 129613, 220, 128697, 132504, 128545, 220, 128697, 133214, 130829, 134076, 129461, 131061, 128480, 129082, 220, 128594, 129051, 220, 131814, 129063, 220, 130008, 130337, 129126, 220, 131814, 128594, 130829, 129807, 220, 134429, 130043, 220, 130337, 132789, 128594, 220, 130610, 130033, 131538, 131763, 135117, 220, 128697, 129022, 131143, 220, 134454, 129461, 129985, 220, 131061, 129082, 13, 366, 268, 29, 11458, 11, 6617, 14016, 6137, 311, 10205, 1633, 6051, 304, 279, 3363, 13, 366, 22524, 29, 51418, 132935, 129025, 220, 129082, 128989, 128594, 128813, 129063, 220, 130226, 129461, 130226, 128594, 220, 131538, 132789, 131160, 128989, 129461, 133545, 128530, 129127, 220, 130337, 130226, 130829, 129461, 130226, 130577, 220, 131143, 220, 135102, 128594, 128438, 220, 131923, 128480, 130829, 131613, 129461, 131061, 130829, 131143, 129613, 220, 130637, 130829, 132751, 220, 131763, 128884, 134429, 131160, 129127, 128585, 220, 128697, 128895, 129461, 135069, 129461, 129113, 220, 129063, 130829, 131814, 128594, 13, 366, 268, 29, 1548, 11335, 304, 1690, 3953, 11, 719, 568, 374, 279, 832, 889, 27772, 813, 477, 1077, 29315, 596, 3560, 21676, 13, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def show_collated_batch(dataset, tokenizer, data_collator, batch_size=4):\n",
    "    \"\"\"Fetches and prints a sample batch after applying the DataCollator.\"\"\"\n",
    "    \n",
    "    # Create DataLoader with DataCollator\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "    \n",
    "    # Get one batch\n",
    "    batch = next(iter(dataloader))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        print(f\"\\n📝 **Sample {i+1}:**\")\n",
    "        print(\"Input IDs:\", batch[\"input_ids\"][i].tolist())\n",
    "        print(\"Attention Mask:\", batch[\"attention_mask\"][i].tolist())\n",
    "\n",
    "        # Decode tokenized input back to text\n",
    "        decoded_text = tokenizer.decode(batch[\"input_ids\"][i], skip_special_tokens=True)\n",
    "        print(\"Decoded Text:\", decoded_text)\n",
    "\n",
    "        if \"labels\" in batch:\n",
    "            print(\"Labels:\", batch[\"labels\"][i].tolist())\n",
    "\n",
    "# Initialize Data Collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Example Usage\n",
    "show_collated_batch(merged_dataset['train'], tokenizer, data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
